{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook generates a data table from a search of SSW Latest Events on the HEK Database, and peforms some basic post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from astropy.time import Time\n",
    "from astropy.time import TimeDelta\n",
    "\n",
    "from sunpy import timeseries as ts\n",
    "from sunpy.net import attrs as a\n",
    "from sunpy.net import hek\n",
    "from sunpy.net import Fido\n",
    "from sunpy.time import parse_time, find_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"D:\\MastersProj\\Data\\goes15\" #Define your data directory here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell searches your specified data directory for downloaded GOES flare data, finds the oldest and most recent flares in order to specify a date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for f in files:\n",
    "        if f.__contains__('.nc') and f.__contains__('sci_gxrs-l2-irrad_g15_d'):\n",
    "            match = re.search(r'd(\\d{8})', f)\n",
    "            date_str = match.group(1)\n",
    "            date = datetime.strptime(date_str, '%Y%m%d')\n",
    "            dates.append(date)\n",
    "\n",
    "datetime_array = np.array(dates, dtype='datetime64[s]')\n",
    "\n",
    "first_date = min(datetime_array)\n",
    "last_date = Time(max(datetime_array)) + TimeDelta(1, format = 'jd') - TimeDelta(1, format ='sec')\n",
    "fl_search = a.Time(first_date, last_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cells generate a .csv files of flare information from the HEK database in the time range specified from the previous cell; for SSW latest events and GOES flare lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of flares in period: 16099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Search database for ALL goes flares\n",
    "res = Fido.search(fl_search, a.hek.EventType(\"FL\"), a.hek.FRM.Name == \"SSW Latest Events\")\n",
    "fullres = res[\"hek\"]\n",
    "\n",
    "#### Reduce the table down to just the info we want\n",
    "srch_res = fullres[\"event_starttime\", \"event_peaktime\",\n",
    "                        \"event_endtime\", \"fl_goescls\", \"hpc_x\", \"hpc_y\", \"hgc_x\", \"hgc_y\",\"hgs_x\", \"hgs_y\",\"event_score\",\"sum_overlap_scores\",\"ar_noaanum\"]\n",
    "                        # More stuff that could be useful, Heliographic lat lon, and where from\n",
    "                        #[\"hgc_x\", \"hgc_y\", \"frm_name\"]\n",
    "\n",
    "print(f\"Total Number of flares in period: {len(srch_res)}\")\n",
    "print(\"\")\n",
    "srch_res.write(\"GOES15_HEK_Data_SSW.csv\", overwrite = True, format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of flares in period: 14751\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Search database for ALL goes flares\n",
    "res = Fido.search(fl_search, a.hek.EventType(\"FL\"), a.hek.OBS.Observatory == \"GOES\")\n",
    "fullres = res[\"hek\"]\n",
    "\n",
    "#### Reduce the table down to just the info we want\n",
    "srch_res = fullres[\"event_starttime\", \"event_peaktime\",\n",
    "                        \"event_endtime\", \"fl_goescls\",\"ar_noaanum\"]\n",
    "                        # More stuff that could be useful, Heliographic lat lon, and where from\n",
    "                        #[\"hgc_x\", \"hgc_y\", \"frm_name\"]\n",
    "\n",
    "print(f\"Total Number of flares in period: {len(srch_res)}\")\n",
    "print(\"\")\n",
    "srch_res.write(\"GOES15_HEK_Data_GOES.csv\", overwrite = True, format=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Post Processing of the Flare List."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of duplicates within each individual flare list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_SSW = pd.read_csv(\"GOES15_HEK_Data_SSW.csv\")\n",
    "data_SSW = data_SSW.drop_duplicates(['event_peaktime', 'fl_goescls'])\n",
    "data_SSW['Origin'] = \"SSW\"\n",
    "\n",
    "data_GOES = pd.read_csv(\"GOES15_HEK_Data_GOES.csv\")\n",
    "data_GOES = data_GOES.drop_duplicates(['event_peaktime', 'fl_goescls'])\n",
    "data_GOES['Origin'] = \"GOES\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining both flare lists and getting rid of GOES database flares that exist in the SSW latest events database. The purpose of this is to fill in gaps in the SSW latest events flare list that were present in early 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.concat([data_SSW, data_GOES],axis = 0)\n",
    "data_full = data_full.sort_values(by = ['event_starttime', 'Origin'])\n",
    "data_full = data_full.drop_duplicates(['event_peaktime', 'fl_goescls'], keep = \"last\")\n",
    "data_full = data_full.sort_values(by = ['event_starttime'])\n",
    "data_full = data_full.reset_index(drop = True)\n",
    "data_full.to_csv(\"GOES15_HEK_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_full"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a proximity flag for overlapped flares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Proximity Flag'] = False\n",
    "data.at[0, 'Proximity Flag'] = False  # add this line to set the first row to False\n",
    "\n",
    "for i in range(1, len(data)):\n",
    "    if (pd.to_datetime(data.iloc[i]['event_starttime']) - pd.to_datetime(data.iloc[i-1]['event_endtime'])).total_seconds() / 60 <= 30:\n",
    "        data.at[i, 'Proximity Flag'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were: 0 duplicates removed\n"
     ]
    }
   ],
   "source": [
    "data1 = data.drop_duplicates(subset = ['event_peaktime','fl_goescls'])\n",
    "data1 = data1.reset_index(drop=True)\n",
    "print(f\"There were: {len(data) - len(data1)} duplicates removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(\"GOES15_HEK_Data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hot_onsets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62a2b8ad637c63baaf45e2cce9d4a159ca450ba6124aa82e6d4dc02e44296dbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
